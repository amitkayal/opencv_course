{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Image_Classification_CNN_LibTorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Ryyeej9_R1",
        "colab_type": "text"
      },
      "source": [
        "# <font style=\"color:rgb(50,120,229)\">Motivation </font>\n",
        "Earlier, we have used Multilayer Perceptron for image classification on Fashion MNIST. We have achieved accuracy of 85% on test data. To improve the accuracy further if we choose to add more hidden layers, the number of parameters will grow high (N1xN2xN3..., N(ith layer) - number of nodes) and also leads to redundancy in learning. Another disadvantage of MLP is it doesn't learn spatial information. In Convolutional Neural Network, we can account for spatial information and also increase the number of layers where the weights are smaller and shared. This makes CNN easy to train than MLP for more number of layers. Now, lets see how CNN learns spatial information\n",
        "compared to MLP.\n",
        "\n",
        "Given below is an example of the first test image which corresponds to the `Boot` class. The image is shifted by some amount to the top and bottom. The classifier predicts it correctly for the centered image but fails in the other two cases. To make it work for these images, either we have to train separate MLPs for different locations or we have to make sure that we have all these variations in the training set as well, which I would say is difficult, if not impossible.\n",
        "\n",
        "<img src=\"https://www.learnopencv.com/wp-content/uploads/2019/12/mlp-shift-failure.jpg\" width=\"900\">\n",
        "\n",
        "The Fully connected network tries to learn global features or patterns. It acts as a good classifier.\n",
        "\n",
        "Another major problem with a fully connected classifier is that the number of parameters increases very fast since each node in layer L is connected to a node in layer L-1. So it is not feasible to design very deep networks using an MLP structure alone.\n",
        "\n",
        "Both the above problems are solved to a great extent by using Convolutional Neural Networks.\n",
        "\n",
        "Here, we are going to implement CNN using libtorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXeiaMo89_R3",
        "colab_type": "text"
      },
      "source": [
        "## <font style=\"color:rgb(50,120,229)\">Import Libraries </font>\n",
        "\n",
        "Import required libraries and define constants like\n",
        "- batchSize\n",
        "- epoch\n",
        "- logInterval\n",
        "- Images path of train and test\n",
        "- Labels path of train and test\n",
        "- Torch device(it is specified to use GPU if available else CPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj6KkrY09_R4",
        "colab_type": "text"
      },
      "source": [
        "```cpp\n",
        "#include <stdint.h>\n",
        "#include <torch/torch.h>\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <opencv2/core/core.hpp>\n",
        "#include <opencv2/opencv.hpp>\n",
        "#include <opencv2/highgui/highgui.hpp>\n",
        "#include \"read-mnist.h\"\n",
        "\n",
        "struct Options {\n",
        "  int batchSize = 256; //Batch size\n",
        "  size_t epochs = 10; // Number of epochs\n",
        "  size_t logInterval = 20;\n",
        "  //Paths to train and test images and labels\n",
        "  const char* trainImagesPath = \"train-images-idx3-ubyte\";\n",
        "  const char* trainLabelsPath = \"train-labels-idx1-ubyte\";\n",
        "  const char* testImagesPath = \"t10k-images-idx3-ubyte\";\n",
        "  const char* testLabelsPath = \"t10k-labels-idx1-ubyte\";\n",
        "  torch::DeviceType device = torch::kCPU;\n",
        "};\n",
        "\n",
        "static Options options;\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUONI0Qu9_R6",
        "colab_type": "text"
      },
      "source": [
        "# <font style=\"color:rgb(50,120,229)\">1. Convolutional Neural network</font>\n",
        "We will use Convolutional Neural Network of 3 convolutional blocks and 3 fully connected layers(including output). Convolutional block consists of 2 convolutional layers, 1 max pooling layer and then dropout to be added.\n",
        "\n",
        "All the layers are defined with parameters and registered as modules. Then the network is implemented using these layers in order along with activation functions.\n",
        "\n",
        "We need to apply log softmax on the output to get the probabilities of all the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcp5nuqx9_R7",
        "colab_type": "text"
      },
      "source": [
        "```cpp\n",
        "struct Net: torch::nn::Module {\n",
        "    Net() {\n",
        "        //Convolutional layer 1: 32 filters, 3x3 Kernel size, padding=1\n",
        "        //torch::nn::Conv2dOptions(input_channels, output_channels, kernel_size).padding(p).stride(s) and similarly other options\n",
        "        conv1_1 = register_module(\"conv1_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(1, 32, 3).padding(1)));\n",
        "        //Convolutional layer 2: 32 filters, 3x3 Kernel size, padding=0\n",
        "        conv1_2 = register_module(\"conv1_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(32, 32, 3)));\n",
        "        // Insert pool layer (poolsize-[2,2])\n",
        "        dp1 = register_module(\"dp1\", torch::nn::Dropout(0.25));\n",
        "\n",
        "        //Convolutional layer 3: 64 filters, 3x3 Kernel size, padding=1\n",
        "        conv2_1 = register_module(\"conv2_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(32, 64, 3).padding(1)));\n",
        "        //Convolutional layer 4: 64 filters, 3x3 Kernel size, padding=0\n",
        "        conv2_2 = register_module(\"conv2_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(64, 64, 3)));\n",
        "        // Insert pool layer (poolsize-[2,2])\n",
        "        dp2 = register_module(\"dp2\", torch::nn::Dropout(0.25));\n",
        "\n",
        "        //Convolutional layer 5: 64 filters, 3x3 Kernel size, padding=1\n",
        "        conv3_1 = register_module(\"conv3_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(64, 64, 3).padding(1)));\n",
        "        //Convolutional layer 6: 32 filters, 3x3 Kernel size, padding=0\n",
        "        conv3_2 = register_module(\"conv3_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(64, 64, 3)));\n",
        "        // Insert pool layer (poolsize-[2,2])\n",
        "        dp3 = register_module(\"dp3\", torch::nn::Dropout(0.25));\n",
        "        \n",
        "        //Fully connected layer - torch::nn:Linear(input_size, output_size(number of neurons))\n",
        "        fc1 = register_module(\"fc1\", torch::nn::Linear(64, 512));\n",
        "        fc2 = register_module(\"fc2\", torch::nn::Linear(512, 512));\n",
        "        fc3 = register_module(\"fc3\", torch::nn::Linear(512, 10));\n",
        "    }\n",
        "\n",
        "    // Implement Algorithm\n",
        "    torch::Tensor forward(torch::Tensor x) {\n",
        "        x = torch::relu(conv1_1->forward(x));\n",
        "        x = torch::relu(conv1_2->forward(x));\n",
        "        x = torch::max_pool2d(x, 2);\n",
        "        x = dp1(x);\n",
        "\n",
        "        x = torch::relu(conv2_1->forward(x));\n",
        "        x = torch::relu(conv2_2->forward(x));\n",
        "        x = torch::max_pool2d(x, 2);\n",
        "        x = dp2(x);\n",
        "\n",
        "        x = torch::relu(conv3_1->forward(x));\n",
        "        x = torch::relu(conv3_2->forward(x));\n",
        "        x = torch::max_pool2d(x, 2);\n",
        "        x = dp3(x);\n",
        "\n",
        "        x = x.view({-1, 64});\n",
        "\n",
        "        x = torch::relu(fc1->forward(x));\n",
        "        x = torch::relu(fc2->forward(x));\n",
        "        x = fc3->forward(x);\n",
        "\n",
        "        return torch::log_softmax(x, 1);\n",
        "    }\n",
        "\n",
        "    // Declare layers\n",
        "    torch::nn::Conv2d conv1_1{nullptr};\n",
        "    torch::nn::Conv2d conv1_2{nullptr};\n",
        "    torch::nn::Conv2d conv2_1{nullptr};\n",
        "    torch::nn::Conv2d conv2_2{nullptr};\n",
        "    torch::nn::Conv2d conv3_1{nullptr};\n",
        "    torch::nn::Conv2d conv3_2{nullptr};\n",
        "    torch::nn::Dropout dp1{nullptr}, dp2{nullptr}, dp3{nullptr};\n",
        "\n",
        "    torch::nn::Linear fc1{nullptr}, fc2{nullptr}, fc3{nullptr};\n",
        "};\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oakFG4M39_R8",
        "colab_type": "text"
      },
      "source": [
        "# <font style=\"color:rgb(50,120,229)\">2. Load the Data</font>\n",
        "In libtorch, Fashion MNIST is not a built-in dataset so we need to custom load the data. This dataset is available in ubyte(eg:train-images-idx3-ubyte) format files. This format files are explained here - http://yann.lecun.com/exdb/mnist/.\n",
        "\n",
        "We have 2 different files for images and labels in case of both train and test data. We will use Custom Dataset Class like we did for linear regression earlier to process the data and convert to tensor form. Normalization of images is also performed in read-mnist.h after tensor conversion. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTjxjKfi9_R8",
        "colab_type": "text"
      },
      "source": [
        "```cpp\n",
        "//Read images from ubyte format and convert to tensors\n",
        "torch::Tensor process_images(const std::string& root, bool train) {\n",
        "  const auto path = root + (train ? options.trainImagesPath: options.testImagesPath); //images_path\n",
        "  auto images = read_mnist_images(path);\n",
        "\n",
        "  return images;\n",
        "}\n",
        "\n",
        "//Read labels from ubyte format and convert to tensors\n",
        "torch::Tensor process_labels(const std::string& root, bool train) {\n",
        "  const auto path = root + (train ? options.trainLabelsPath: options.testLabelsPath); //labels_path\n",
        "  auto labels = read_mnist_labels(path);\n",
        "\n",
        "  return labels;\n",
        "}\n",
        "\n",
        "\n",
        "//Use CustomDataset class to load any type of dataset other than inbuilt datasets\n",
        "class CustomDataset : public torch::data::datasets::Dataset<CustomDataset> {\n",
        "    private:\n",
        "    // data should be 2 tensors\n",
        "        torch::Tensor images, labels;\n",
        "        size_t img_size;\n",
        "    public:\n",
        "        CustomDataset(const std::string& root, bool train) {\n",
        "            images = process_images(root, train);\n",
        "            labels = process_labels(root, train);\n",
        "            img_size = images.size(0);\n",
        "        }\n",
        "\n",
        "        //Returns the data sample at the given `index\n",
        "        torch::data::Example<> get(size_t index) override {\n",
        "            // This should return {torch::Tensor, torch::Tensor}\n",
        "            torch::Tensor img = images[index];\n",
        "            torch::Tensor label = labels[index];\n",
        "            return {img.clone(), label.clone()};\n",
        "        };\n",
        "    \n",
        "    torch::optional<size_t> size() const override {\n",
        "        return img_size;\n",
        "    };\n",
        "};\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD49oxFA9_R9",
        "colab_type": "text"
      },
      "source": [
        "# <font style=\"color:rgb(50,120,229)\">3. Train the Model</font>\n",
        "Training data is passed in set of batches and **negative log likelihood** loss function is used to calculate the loss. Then the loss function is passed through **Adam** optimizer which is defined in the main().\n",
        "\n",
        "Following are the major functions of training the network\n",
        "- Initialize the network in training mode\n",
        "        \n",
        "        network->train()\n",
        "- Uses negative log likelihood loss\n",
        "        \n",
        "        torch::nll_loss(output, targets)\n",
        "- Computes the gradients in the network\n",
        "        \n",
        "        loss.backward()\n",
        "- Updates the parameters of the network using the computed gradients\n",
        "        \n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OerjBG8B9_R-",
        "colab_type": "text"
      },
      "source": [
        "```cpp\n",
        "template <typename DataLoader>\n",
        "void train(std::shared_ptr<Net> network, DataLoader& loader, torch::optim::Optimizer& optimizer, size_t epoch, size_t data_size) {\n",
        "  size_t index = 0;\n",
        "  //Set network in the training mode\n",
        "  network->train();\n",
        "  float Loss = 0, Acc = 0;\n",
        "\n",
        "  for (auto& batch : loader) {\n",
        "    auto data = batch.data.to(options.device);\n",
        "    auto targets = batch.target.to(options.device).view({-1});\n",
        "    // Execute the model on the input data\n",
        "    auto output = network->forward(data);\n",
        "\n",
        "    //Using mean square error loss function to compute loss\n",
        "    auto loss = torch::nll_loss(output, targets);\n",
        "    auto acc = output.argmax(1).eq(targets).sum();\n",
        "\n",
        "    // Reset gradients\n",
        "    optimizer.zero_grad();\n",
        "    // Compute gradients\n",
        "    loss.backward();\n",
        "    //Update the parameters\n",
        "    optimizer.step();\n",
        "\n",
        "    Loss += loss.template item<float>();\n",
        "    Acc += acc.template item<float>();\n",
        "  }\n",
        "\n",
        "  if (index++ % options.logInterval == 0) {\n",
        "    auto end = data_size;\n",
        "\n",
        "    std::cout << \"Train Epoch: \" << epoch << \" \" << end << \"/\" << data_size\n",
        "              << \"\\tLoss: \" << Loss / end << \"\\tAcc: \" << Acc / end\n",
        "              << std::endl;\n",
        "  }\n",
        "};\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpISefWY9_R_",
        "colab_type": "text"
      },
      "source": [
        "# <font style=\"color:rgb(50,120,229)\">4. Test the Model</font>\n",
        "Similar to the above, the test data is passed through the trained network. Loss is calculated on test data at each epoch. After all epochs, 3 sample outputs and their ground truth are displayed.\n",
        "\n",
        "Following are the major functions of test the network\n",
        "- Initialize the network in testing mode\n",
        "      \n",
        "      network->eval()\n",
        "- Compute negative log likelihood loss\n",
        "    \n",
        "      torch::nll_loss(output, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxSADjl29_SA",
        "colab_type": "text"
      },
      "source": [
        "```cpp\n",
        "void test(std::shared_ptr<Net> network, DataLoader& loader, size_t epoch, size_t data_size) {\n",
        "  network->eval();\n",
        "  size_t index = 0;\n",
        "  float Loss = 0, Acc = 0;\n",
        "  int display_count = 0;\n",
        "\n",
        "  for (const auto& batch : loader) {\n",
        "    auto data = batch.data.to(options.device);\n",
        "    auto targets = batch.target.to(options.device).view({-1});\n",
        "\n",
        "    auto output = network->forward(data);\n",
        "\n",
        "    //To display 3 test image and its output\n",
        "    if (display_count < 3 && epoch== options.epochs) {\n",
        "      cv::Mat test_image(28,28,CV_8UC1);\n",
        "      torch::Tensor tensor = data[display_count].mul_(255).clamp(0,255).to(torch::kU8);\n",
        "      tensor = tensor.to(torch::kCPU);\n",
        "      std::memcpy((void*)test_image.data,tensor.data_ptr(),sizeof(torch::kU8)*tensor.numel());\n",
        "\n",
        "      std::cout << \"***** TESTING on TEST IMAGE \" << display_count << \" *****\" << std::endl;\n",
        "      std::cout << \"GroundTruth: \" << targets[display_count].template item<float>()\n",
        "                << \", Prediction: \" << output[display_count].argmax() << std::endl;\n",
        "      std::cout << \"Output Probabilities\" << std::endl;\n",
        "      for (int i =0; i < output[display_count].size(0); i++) {\n",
        "        std::cout << \"Class: \" << i << \" \" << torch::exp(output[display_count])[i].template item<float>()  << std::endl;\n",
        "      }\n",
        "      cv::imwrite(\"OUTPUT_GT_\" + std::to_string(targets[display_count].template item<int>()) +\n",
        "                  \"_Pred_\" + std::to_string(output[display_count].argmax().template item<int>()) + \".jpg\", test_image);\n",
        "      std::cout << \"Outputs saved, Please checkout the output images\" << std::endl;\n",
        "\n",
        "      display_count++;\n",
        "    }\n",
        "\n",
        "    auto loss = torch::nll_loss(output, targets);\n",
        "    auto acc = output.argmax(1).eq(targets).sum();\n",
        "\n",
        "    Loss += loss.template item<float>();\n",
        "    Acc += acc.template item<float>();\n",
        "  }\n",
        "\n",
        "  //This block can be used inside for loop to see the training within each epoch\n",
        "  if (index++ % options.logInterval == 0) {\n",
        "    options.loss_acc_test << std::to_string(Loss/data_size) + \",\" + std::to_string(Acc/data_size) << std::endl;\n",
        "    std::cout << \"Val Epoch: \" << epoch\n",
        "              << \"\\tVal Loss: \" << Loss/data_size << \"\\tVal ACC:\"<< Acc/data_size << std::endl;\n",
        "  }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM7rNqf99_SA",
        "colab_type": "text"
      },
      "source": [
        "# <font style=\"color:rgb(50,120,229)\">5. Main function</font>\n",
        "Main function contains following steps:\n",
        "- **Data Processing**\n",
        "    - Data is processed within Custom Dataset Constructer and converted to tensors. Here, we already have separate\n",
        "      train and test data.\n",
        "          auto dataset = torch::data::datasets::MNIST(\"./mnist\")\n",
        "            .map(torch::data::transforms::Normalize<>(0.5, 0.5))\n",
        "            .map(torch::data::transforms::Stack<>());\n",
        "- **Data Loader**\n",
        "    - This provides options for batch size, number of workers to be used to speed up the data loading.\n",
        "            auto data_loader = torch::data::make_data_loader(\n",
        "                std::move(dataset),\n",
        "                torch::data::DataLoaderOptions().batch_size(kBatchSize).workers(2));\n",
        "- **Model Initialization**\n",
        "    - Define network parameters\n",
        "            struct Net : torch::nn::Module {};\n",
        "                void a(std::shared_ptr<Net> net) { }\n",
        "                int main() {\n",
        "                  auto net = std::make_shared<Net>();\n",
        "                  a(net);\n",
        "                }\n",
        "- **Training**\n",
        "    - Define the optimizer and call the train function epoch number of times and observe the loss values.\n",
        "            torch::optim::Adam generator_optimizer(\n",
        "            generator->parameters(), torch::optim::AdamOptions(2e-4).beta1(0.5));\n",
        "            train(net, *train_loader, generator_optimizer, epoch_number, train_dataset_size);\n",
        "- **Testing**\n",
        "    - Call the test function in each epoch and observe the loss values.\n",
        "            test(net, *test_loader, test_dataset_size);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe-NyGTV9_SB",
        "colab_type": "text"
      },
      "source": [
        "```cpp\n",
        "int main() {\n",
        "  //Use CUDA for computation if available\n",
        "  if (torch::cuda::is_available())\n",
        "    options.device = torch::kCUDA;\n",
        "  std::cout << \"Running on: \"\n",
        "            << (options.device == torch::kCUDA ? \"CUDA\" : \"CPU\") << std::endl;\n",
        "  //Path to Fashion Mnist\n",
        "  std::string root_string = \"./fashion-mnist/\";\n",
        "  bool isTrain = true; //Flag to create train or test data\n",
        "\n",
        "  //Uses Custom Dataset Class to load train data. Apply stack collation which takes \n",
        "  //batch of tensors and stacks them into single tensor along the first dimension\n",
        "  auto train_dataset = CustomDataset(root_string, isTrain).map(torch::data::transforms::Stack<>());\n",
        "  //Data Loader provides options to speed up the data loading like batch size, number of workers\n",
        "  auto train_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(\n",
        "    std::move(train_dataset), options.batchSize);\n",
        "  auto train_size = train_dataset.size().value();\n",
        "\n",
        "  //Process and load test dat similar to above\n",
        "  auto test_dataset = CustomDataset(root_string, false).map(torch::data::transforms::Stack<>());\n",
        "  auto test_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(\n",
        "    std::move(test_dataset), options.batchSize);\n",
        "  auto test_size = test_dataset.size().value();\n",
        "\n",
        "  //Create Feed forward network\n",
        "  auto net = std::make_shared<Net>();\n",
        "  //Moving model parameters to correct device\n",
        "  net->to(options.device);\n",
        "  // torch::load(net, \"net.pt\"); /*To use trained model*/\n",
        "\n",
        "  //Using Adam optimizer with beta1 as 0.5\n",
        "  torch::optim::Adam optimizer(net->parameters(), torch::optim::AdamOptions(5e-4).beta1(0.5));\n",
        "\n",
        "  for (size_t i = 0; i < options.epochs; i++) {\n",
        "    /*Run the training for all epochs*/\n",
        "    train(net, *train_loader, optimizer, i + 1, train_size);\n",
        "    std::cout << std::endl;\n",
        "    /*Run on the validation set for all epochs*/\n",
        "    test(net, *test_loader, i+1, test_size);\n",
        "    /*Save the network*/\n",
        "    torch::save(net, \"net.pt\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goUeEGyR9_SC",
        "colab_type": "text"
      },
      "source": [
        "# <font style=\"color:rgb(50,120,229)\">6. Run inference on saved model</font>\n",
        "We load the saved network to run inference on test data. Initialize the network and then use\n",
        "        \n",
        "       torch::load(network, path_to_network)\n",
        "to load the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po4QZo_U9_SD",
        "colab_type": "text"
      },
      "source": [
        "```cpp\n",
        "int main() {\n",
        "    /*Path to Fashion Mnist*/\n",
        "    std::string root_string = \"./fashion-mnist/\";\n",
        "\n",
        "    /*Process and load test dat similar to above*/\n",
        "    auto test_dataset = CustomDataset(root_string, false).map(torch::data::transforms::Stack<>());\n",
        "    auto test_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(\n",
        "        std::move(test_dataset), options.batch_size);\n",
        "    auto test_size = test_dataset.size().value();\n",
        "\n",
        "    auto net = std::make_shared<Net>();\n",
        "    torch::load(net, \"net.pt\");\n",
        "    test(net, *test_loader, options.epochs, test_size);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C4jkRi59_SE",
        "colab_type": "text"
      },
      "source": [
        "# <font style=\"color:blue\">Steps to Compile and Run the Code on Google Colab</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Que-9WAp9_SF",
        "colab_type": "text"
      },
      "source": [
        "## <font style=\"color:green\">Download LibTorch</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXBnlW-S9_SG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e62b28c1-9e31-46ab-9579-42ae7c032957"
      },
      "source": [
        "!wget https://download.pytorch.org/libtorch/cu101/libtorch-shared-with-deps-1.3.1.zip -O libtorch.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-04 19:13:01--  https://download.pytorch.org/libtorch/cu101/libtorch-shared-with-deps-1.3.1.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.224.29.48, 13.224.29.19, 13.224.29.73, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.224.29.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 740942259 (707M) [application/zip]\n",
            "Saving to: ‘libtorch.zip’\n",
            "\n",
            "libtorch.zip        100%[===================>] 706.62M  50.9MB/s    in 14s     \n",
            "\n",
            "2020-01-04 19:13:16 (49.1 MB/s) - ‘libtorch.zip’ saved [740942259/740942259]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqXOEgc79_SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip libtorch.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U-swR-s9_SM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r libtorch.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a23ubXN-9_SP",
        "colab_type": "text"
      },
      "source": [
        "## <font style=\"color:green\">Download Code</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8GawlrN9_SP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "388405ce-59ab-4c00-92a4-1ae7c2d69149"
      },
      "source": [
        "!wget \"https://www.dropbox.com/s/v2l8r6b722hbiqr/cnn.zip?dl=1\" -O cnn.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-04 19:13:43--  https://www.dropbox.com/s/v2l8r6b722hbiqr/cnn.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/v2l8r6b722hbiqr/cnn.zip [following]\n",
            "--2020-01-04 19:13:43--  https://www.dropbox.com/s/dl/v2l8r6b722hbiqr/cnn.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc6eaad76ab39949c227ecedf9cf.dl.dropboxusercontent.com/cd/0/get/AvhstswcU7MXXGGO2qzmshat_cThl6Lfn2I94McZd8oz_6ArWAE4lpbnVWObvWX41-RQYFb58xj3Ida7JEqzKvIaMVBOc6ojPfcuGYNtqtiCGpedBPz0t-DB4ZS2syMJDsU/file?dl=1# [following]\n",
            "--2020-01-04 19:13:43--  https://uc6eaad76ab39949c227ecedf9cf.dl.dropboxusercontent.com/cd/0/get/AvhstswcU7MXXGGO2qzmshat_cThl6Lfn2I94McZd8oz_6ArWAE4lpbnVWObvWX41-RQYFb58xj3Ida7JEqzKvIaMVBOc6ojPfcuGYNtqtiCGpedBPz0t-DB4ZS2syMJDsU/file?dl=1\n",
            "Resolving uc6eaad76ab39949c227ecedf9cf.dl.dropboxusercontent.com (uc6eaad76ab39949c227ecedf9cf.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc6eaad76ab39949c227ecedf9cf.dl.dropboxusercontent.com (uc6eaad76ab39949c227ecedf9cf.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30884209 (29M) [application/binary]\n",
            "Saving to: ‘cnn.zip’\n",
            "\n",
            "cnn.zip             100%[===================>]  29.45M  35.8MB/s    in 0.8s    \n",
            "\n",
            "2020-01-04 19:13:45 (35.8 MB/s) - ‘cnn.zip’ saved [30884209/30884209]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avg7I3XM9_SS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "14408f86-a0a6-4291-9e08-d00335c5534d"
      },
      "source": [
        "!unzip cnn.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cnn.zip\n",
            "   creating: cnn/\n",
            "  inflating: cnn/CMakeLists.txt      \n",
            "  inflating: cnn/CNN.cpp             \n",
            "   creating: cnn/fashion-mnist/\n",
            "  inflating: cnn/fashion-mnist/t10k-images-idx3-ubyte  \n",
            "  inflating: cnn/fashion-mnist/t10k-labels-idx1-ubyte  \n",
            "  inflating: cnn/fashion-mnist/train-images-idx3-ubyte  \n",
            "  inflating: cnn/fashion-mnist/train-labels-idx1-ubyte  \n",
            "  inflating: cnn/read-mnist.h        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSs6-JI89_SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"cnn\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HcKwwnt9_SY",
        "colab_type": "text"
      },
      "source": [
        "## <font style=\"color:green\">Compile</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-sClSaG9_SY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "1a3d59e1-6a60-434a-878b-9b4c0023c3e0"
      },
      "source": [
        "!cmake -DCMAKE_PREFIX_PATH=$PWD/../libtorch ."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.4.0\n",
            "-- The CXX compiler identification is GNU 7.4.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Found CUDA: /usr/local/cuda (found version \"10.0\") \n",
            "-- Caffe2: CUDA detected: 10.0\n",
            "-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\n",
            "-- Caffe2: CUDA toolkit directory: /usr/local/cuda\n",
            "-- Caffe2: Header version is: 10.0\n",
            "-- Found CUDNN: /usr/lib/x86_64-linux-gnu/libcudnn.so  \n",
            "-- Found cuDNN: v7.6.5  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\n",
            "-- Autodetected CUDA architecture(s):  6.0\n",
            "-- Added CUDA NVCC flags for: -gencode;arch=compute_60,code=sm_60\n",
            "-- Found torch: /content/libtorch/lib/libtorch.so  \n",
            "-- Found OpenCV: /usr (found version \"3.2.0\") \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/cnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc5mEIsm9_Sb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7d209441-23e4-4e74-96ee-28eae57e8ab8"
      },
      "source": [
        "!make"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[35m\u001b[1mScanning dependencies of target CNN\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/CNN.dir/CNN.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable CNN\u001b[0m\n",
            "[100%] Built target CNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4QFbTuL9_Se",
        "colab_type": "text"
      },
      "source": [
        "## <font style=\"color:green\">Run </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiOtZLH79_Sf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cc6e599-811c-439a-f19e-b47a753de91f"
      },
      "source": [
        "!./CNN"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on: CUDA\n",
            "Train Epoch: 1 60000/60000\tLoss: 0.00383456\tAcc: 0.6178\n",
            "\n",
            "Val Epoch: 1\tVal Loss: 0.00265889\tVal ACC:0.7489\n",
            "Train Epoch: 2 60000/60000\tLoss: 0.00240953\tAcc: 0.761533\n",
            "\n",
            "Val Epoch: 2\tVal Loss: 0.00235918\tVal ACC:0.7637\n",
            "Train Epoch: 3 60000/60000\tLoss: 0.00208635\tAcc: 0.79495\n",
            "\n",
            "Val Epoch: 3\tVal Loss: 0.00183845\tVal ACC:0.818\n",
            "Train Epoch: 4 60000/60000\tLoss: 0.00184256\tAcc: 0.819817\n",
            "\n",
            "Val Epoch: 4\tVal Loss: 0.00167301\tVal ACC:0.8371\n",
            "Train Epoch: 5 60000/60000\tLoss: 0.00167919\tAcc: 0.839083\n",
            "\n",
            "Val Epoch: 5\tVal Loss: 0.00171233\tVal ACC:0.8347\n",
            "Train Epoch: 6 60000/60000\tLoss: 0.0015539\tAcc: 0.849533\n",
            "\n",
            "Val Epoch: 6\tVal Loss: 0.0014753\tVal ACC:0.8609\n",
            "Train Epoch: 7 60000/60000\tLoss: 0.00143016\tAcc: 0.862783\n",
            "\n",
            "Val Epoch: 7\tVal Loss: 0.00141255\tVal ACC:0.8726\n",
            "Train Epoch: 8 60000/60000\tLoss: 0.00134766\tAcc: 0.87135\n",
            "\n",
            "Val Epoch: 8\tVal Loss: 0.00130941\tVal ACC:0.8801\n",
            "Train Epoch: 9 60000/60000\tLoss: 0.0012717\tAcc: 0.87825\n",
            "\n",
            "Val Epoch: 9\tVal Loss: 0.00146549\tVal ACC:0.8596\n",
            "Train Epoch: 10 60000/60000\tLoss: 0.00121746\tAcc: 0.884033\n",
            "\n",
            "Val Epoch: 10\tVal Loss: 0.00154211\tVal ACC:0.8372\n",
            "Train Epoch: 11 60000/60000\tLoss: 0.00115658\tAcc: 0.889667\n",
            "\n",
            "Val Epoch: 11\tVal Loss: 0.0011588\tVal ACC:0.8923\n",
            "Train Epoch: 12 60000/60000\tLoss: 0.0011074\tAcc: 0.894083\n",
            "\n",
            "Val Epoch: 12\tVal Loss: 0.00110491\tVal ACC:0.8961\n",
            "Train Epoch: 13 60000/60000\tLoss: 0.00105453\tAcc: 0.9001\n",
            "\n",
            "Val Epoch: 13\tVal Loss: 0.00108366\tVal ACC:0.8979\n",
            "Train Epoch: 14 60000/60000\tLoss: 0.00102387\tAcc: 0.9041\n",
            "\n",
            "Val Epoch: 14\tVal Loss: 0.00100929\tVal ACC:0.9053\n",
            "Train Epoch: 15 60000/60000\tLoss: 0.00100086\tAcc: 0.9058\n",
            "\n",
            "Val Epoch: 15\tVal Loss: 0.00106871\tVal ACC:0.8993\n",
            "Train Epoch: 16 60000/60000\tLoss: 0.000966144\tAcc: 0.90905\n",
            "\n",
            "Val Epoch: 16\tVal Loss: 0.00101043\tVal ACC:0.9061\n",
            "Train Epoch: 17 60000/60000\tLoss: 0.000937693\tAcc: 0.911933\n",
            "\n",
            "Val Epoch: 17\tVal Loss: 0.000990061\tVal ACC:0.9111\n",
            "Train Epoch: 18 60000/60000\tLoss: 0.000912435\tAcc: 0.9143\n",
            "\n",
            "Val Epoch: 18\tVal Loss: 0.000965707\tVal ACC:0.9101\n",
            "Train Epoch: 19 60000/60000\tLoss: 0.000882282\tAcc: 0.9163\n",
            "\n",
            "Val Epoch: 19\tVal Loss: 0.000937917\tVal ACC:0.9116\n",
            "Train Epoch: 20 60000/60000\tLoss: 0.000870059\tAcc: 0.917683\n",
            "\n",
            "***** TESTING on TEST IMAGE 0 *****\n",
            "GroundTruth: 7, Prediction: 7\n",
            "[ Variable[CUDALongType]{} ]\n",
            "Output Probabilities\n",
            "Class: 0 9.92145e-10\n",
            "Class: 1 1.49024e-08\n",
            "Class: 2 3.95397e-10\n",
            "Class: 3 6.37527e-08\n",
            "Class: 4 1.432e-08\n",
            "Class: 5 7.45895e-05\n",
            "Class: 6 6.85882e-10\n",
            "Class: 7 0.999857\n",
            "Class: 8 2.51434e-07\n",
            "Class: 9 6.83104e-05\n",
            "Outputs saved, Please checkout the output images\n",
            "***** TESTING on TEST IMAGE 1 *****\n",
            "GroundTruth: 2, Prediction: 2\n",
            "[ Variable[CUDALongType]{} ]\n",
            "Output Probabilities\n",
            "Class: 0 0.000349937\n",
            "Class: 1 8.40792e-07\n",
            "Class: 2 0.97467\n",
            "Class: 3 2.41181e-05\n",
            "Class: 4 0.0240544\n",
            "Class: 5 2.5724e-09\n",
            "Class: 6 0.000857343\n",
            "Class: 7 6.43904e-11\n",
            "Class: 8 4.35725e-05\n",
            "Class: 9 4.21541e-09\n",
            "Outputs saved, Please checkout the output images\n",
            "***** TESTING on TEST IMAGE 2 *****\n",
            "GroundTruth: 5, Prediction: 5\n",
            "[ Variable[CUDALongType]{} ]\n",
            "Output Probabilities\n",
            "Class: 0 4.77821e-10\n",
            "Class: 1 3.77774e-12\n",
            "Class: 2 6.26643e-12\n",
            "Class: 3 6.30121e-13\n",
            "Class: 4 8.7402e-14\n",
            "Class: 5 1\n",
            "Class: 6 8.9772e-12\n",
            "Class: 7 7.17851e-08\n",
            "Class: 8 2.70716e-10\n",
            "Class: 9 1.71508e-07\n",
            "Outputs saved, Please checkout the output images\n",
            "Val Epoch: 20\tVal Loss: 0.00100196\tVal ACC:0.9075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8qkL4329_Si",
        "colab_type": "text"
      },
      "source": [
        "## <font style=\"color:blue\">Plot Loss and Accuracy Curves using Matplotlib</font>\n",
        "We will be using the matplotlib library to plot the accuracy and loss curves for visualizing how the loss and acuracy changed while training.\n",
        "\n",
        "We had saved the loss and accuracy for training and test data while training for each epoch. We just load the data from those files and put them in a list and finally plot them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY0t1s3D9_Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"loss_acc_train.txt\",'r') as train_file:\n",
        "  train_data = train_file.readlines()\n",
        "with open(\"loss_acc_test.txt\",'r') as test_file:\n",
        "  test_data = test_file.readlines()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m7ATFWP9_Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss_array = []\n",
        "train_acc_array = []\n",
        "for item in train_data:\n",
        "  loss,acc = item.strip().split(',')\n",
        "  train_loss_array.append(float(loss))\n",
        "  train_acc_array.append(float(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_S8Wryw9_So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss_array = []\n",
        "test_acc_array = []\n",
        "for item in test_data:\n",
        "  loss,acc = item.strip().split(',')\n",
        "  test_loss_array.append(float(loss))\n",
        "  test_acc_array.append(float(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEEyxRah9_Sq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fdab0279-260e-40e1-ea3e-82d76ef604d1"
      },
      "source": [
        "print(train_loss_array)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.003835, 0.00241, 0.002086, 0.001843, 0.001679, 0.001554, 0.00143, 0.001348, 0.001272, 0.001217, 0.001157, 0.001107, 0.001055, 0.001024, 0.001001, 0.000966, 0.000938, 0.000912, 0.000882, 0.00087]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Aak824D9_Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHGiiA6h9_Sy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c3e5b534-2072-48c3-a407-00ed9966eea6"
      },
      "source": [
        "plt.plot(train_loss_array,'b')\n",
        "plt.plot(test_loss_array,'r')\n",
        "plt.title(\"Loss Curves\");"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU1f3/8dcnCVtB9oABggFZJEFF\njdStShEFcQH9WkXbaqu/Wre22rrWatVv26/aVruprVvrVoFaRbS4y6KiQLSIrBJ2MOzIomwhn98f\n5wYmYRImZJmQeT8fj/vIzL3n3jkzhHnn3nPuOebuiIiIlEpLdgVERKR+UTCIiEgZCgYRESlDwSAi\nImUoGEREpAwFg4iIlKFgEBGRMhQM0uCY2WIzG5Sk184ys8fNrMjMNpvZXDO7y8yaJ6M+IvtDwSBS\nQ8ysLfAB0Aw43t0PAk4DWgOH7sfxMmq2hiKJUTBISjGzH5hZoZmtN7OxZtYpWm9m9oCZrTazTWb2\nqZn1jbYNNbPZ0RnACjO7oYLD/xTYDHzH3RcDuPsyd/+Ju88wsxwz89gvfDObYGb/L3r8PTN7P6rH\nOuB/zeyL0npEZTLNbKuZdYien2Vm06Nyk83siJiyN0f13Wxm88zs1Br9MKXBUjBIyjCzgcD/ARcA\nWcASYGS0+XTgZKAX0Coqsy7a9jjww+gMoC/wTgUvMQh4wd1LqlHNrwMLgY7A3cALwEUx2y8AJrr7\najM7CngC+CHQDvgbMNbMmphZb+Ba4Nio3oOBxdWol6QQBYOkkm8DT7j7x+6+HbgVON7McoCdwEHA\nYYC5+xx3L4r22wnkmllLd9/g7h9XcPx2QFEF2xL1ubv/2d2L3X0r8E9gRMz2i6N1AFcAf3P3Ke6+\ny92fBLYDxwG7gCZRvRu5+2J3X1DNukmKUDBIKulEOEsAwN23EM4KOrv7O8BfgAeB1Wb2iJm1jIr+\nDzAUWGJmE83s+AqOv45wJlIdy8o9Hw98zcy+HgVYP+DFaNshwM+iy0hfmNkXQDbQyd0LgeuAO6P3\nM7L0spnIvigYJJV8TvgyBSDqKdQOWAHg7n9y92OAXMIlpRuj9dPcfRjQARgDjK7g+G8B55pZRf+v\nvox+fi1m3cHlypQZ7tjdd0Wvd1G0vOLum6PNy4Bfu3vrmOVr7v5ctO8/3f2k6D07cG8F9RIpQ8Eg\nDVUjM2sas2QAzwHfN7N+ZtYE+A0wxd0Xm9mx0V/ljQhf4NuAEjNrbGbfNrNW7r4T2ARU1IZwP9AS\neNLMDgEws85mdr+ZHeHuawgh9B0zSzezy0ist9I/gQsJl8L+GbP+UeDKqN5mZs3N7EwzO8jMepvZ\nwOh9bgO2VlJvkTIUDNJQjSN8GZYud7r7W8DtwL8JbQGHsuf6fUvCF+0GwuWmdcBvo23fBRab2Sbg\nSsIX9F7cfT1wAqFNYoqZbQbeBjYChVGxHxDORNYBecDkfb0Rd59CCKtOwKsx6wui4/0lqnch8L1o\ncxPgHmAtsJJwtnPrvl5LBEIjW7LrICIi9YjOGEREpAwFg4iIlKFgEBGRMhQMIiJSRoMYpKt9+/ae\nk5OT7GqIiBxQPvroo7Xunll+fYMIhpycHAoKCpJdDRGRA4qZLYm3XpeSRESkDAWDiIiUoWAQEZEy\nFAwiIlKGgkFERMpQMIiISBkKBhERKSOlg2HcOLjnnmTXQkSkfknpYHj7bbj7bijR9CUiIruldDDk\n5cHWrbBoUbJrIiJSf6R8MADMnJnceoiI1CcpHQy5ueHnrFnJrYeISH2S0sFw0EHQtauCQUQkVkoH\nA0DfvgoGEZFYKR8MeXkwdy4UFye7JiIi9YOCIQ+2b4cFC5JdExGR+kHBEPVM0uUkEZEg5YOhT5/w\nU8EgIhKkfDA0bw7duikYRERKpXwwgHomiYjEUjAQ2hnmzYOdO5NdExGR5FMwEIJh506YPz/ZNRER\nST4FA+qZJCISS8EAHHYYpKUpGEREQMEAQLNm0L27gkFEBBQMu6lnkohIoGCI5OWFxuft25NdExGR\n5EooGMxsiJnNM7NCM7slzvYmZjYq2j7FzHJitt0arZ9nZoOjdU3NbKqZfWJms8zsrpjy/zCzRWY2\nPVr6Vf9t7lteXhhI77PP6uLVRETqr30Gg5mlAw8CZwC5wEVmlluu2OXABnfvATwA3BvtmwuMAPKA\nIcBD0fG2AwPd/UigHzDEzI6LOd6N7t4vWqZX6x0mSD2TRESCRM4Y+gOF7r7Q3XcAI4Fh5coMA56M\nHj8PnGpmFq0f6e7b3X0RUAj092BLVL5RtHg130u19O4N6ekKBhGRRIKhM7As5vnyaF3cMu5eDGwE\n2lW2r5mlm9l0YDXwprtPiSn3azObYWYPmFmTKryf/dakCfTooWAQEUla47O773L3fkAXoL+Z9Y02\n3QocBhwLtAVujre/mV1hZgVmVrBmzZoaqZN6JomIJBYMK4DsmOddonVxy5hZBtAKWJfIvu7+BTCe\n0AaBuxdFl5q2A38nXMrai7s/4u757p6fmZmZwNvYt7w8KCyEbdtq5HAiIgekRIJhGtDTzLqZWWNC\nY/LYcmXGApdGj88H3nF3j9aPiHotdQN6AlPNLNPMWgOYWTPgNGBu9Dwr+mnAcGBmdd5gVeTlQUlJ\nmOpTRCRVZeyrgLsXm9m1wOtAOvCEu88ys7uBAncfCzwOPG1mhcB6QngQlRsNzAaKgWvcfVf05f9k\n1EMpDRjt7q9EL/msmWUCBkwHrqzJN1yZ2J5J/eqkk6yISP1j4Q/7A1t+fr4XFBRU+zg7doSJe268\nEX7zmxqomIhIPWZmH7l7fvn1uvM5RuPG0KuXGqBFJLUpGMpRzyQRSXUKhnLy8mDhQvjqq2TXREQk\nORQM5eTlgTvMmZPsmoiIJIeCoRyNmSQiqU7BUE6PHqERWsEgIqlKwVBORkYYUE/BICKpSsEQh3om\niUgqUzDEkZcHixfDli37LCoi0uAoGOIobYCePTu59RARSQYFQxzqmSQiqUzBEEf37tC0qYJBRFKT\ngiGO9HQ47DAFg4ikJgVDBdQzSURSlYKhAnl5sGwZbNyY7JqIiNQtBUMF1DNJRFKVgqEC6pkkIqlK\nwVCBnBz42tcUDCKSehQMFUhLgz59FAwiknoUDJXo2xdmzkx2LURE6paCoRJ5eVBUBBs2JLsmIiJ1\nR8FQCTVAi0gqUjBUQsEgIqlIwVCJrl2hRQsFg4ikFgVDJcwgN1fBICKpJaFgMLMhZjbPzArN7JY4\n25uY2aho+xQzy4nZdmu0fp6ZDY7WNTWzqWb2iZnNMrO7Ysp3i45RGB2zcfXf5v5TzyQRSTX7DAYz\nSwceBM4AcoGLzCy3XLHLgQ3u3gN4ALg32jcXGAHkAUOAh6LjbQcGuvuRQD9giJkdFx3rXuCB6Fgb\nomMnTV4erF4Na9cmsxYiInUnkTOG/kChuy909x3ASGBYuTLDgCejx88Dp5qZRetHuvt2d18EFAL9\nPSidOLNRtHi0z8DoGETHHL6f761GqAFaRFJNIsHQGVgW83x5tC5uGXcvBjYC7Srb18zSzWw6sBp4\n092nRPt8ER2jotci2v8KMysws4I1a9Yk8Db2j4JBRFJN0hqf3X2Xu/cDugD9zaxvFfd/xN3z3T0/\nMzOzdioJdO4MLVsqGEQkdSQSDCuA7JjnXaJ1ccuYWQbQCliXyL7u/gUwntAGsQ5oHR2joteqU2bh\nrEHBICKpIpFgmAb0jHoLNSY0Jo8tV2YscGn0+HzgHXf3aP2IqNdSN6AnMNXMMs2sNYCZNQNOA+ZG\n+4yPjkF0zJf2/+3VjNKeSe7JromISO3bZzBE1/uvBV4H5gCj3X2Wmd1tZudExR4H2plZIfBT4JZo\n31nAaGA28BpwjbvvArKA8WY2gxA8b7r7K9GxbgZ+Gh2rXXTspMrLg3XrQu8kEZGGzrwB/Bmcn5/v\nBQUFtXb8t96C006Dt9+GgQNr7WVEROqUmX3k7vnl1+vO5wSoZ5KIpBIFQwIOPhjatFEwiEhqUDAk\nQD2TRCSVKBgSpJ5JIpIqFAwJysuDL74IM7qJiDRkCoYEqQFaRFKFgiFBCgYRSRUKhgR16ADt2ysY\nRKThUzBUQV6eJu0RkYZPwVAFffvC7NnqmSQiDZuCoQry8mDTJli+PNk1ERGpPQqGKlADtIikAgVD\nFSgYRCQVKBiqoF076NhRwSAiDZuCoYrUM0lEGrrUDoYdO2DevCrtUtozqaSkluokIpJkqR0MV1wB\np5xSpW5GeXnw5ZewdGkt1ktEJIlSOxhuuil8y//P/8C2bQntogZoEWnoUjsYcnPhqadg6lS45pqE\n7lxTMIhIQ5fawQBw7rnwi1/AE0/Aww/vs3jr1tCpk4JBRBouBQPAXXfBmWfCT34C7767z+LqmSQi\nDZmCASAtDZ55Brp1g/PP32djdN++MGeOeiaJSMOkYCjVujWMGQNffQXnnVdpY3ReHmzdCosW1WH9\nRETqiIIhVm4uPP00TJsGV19dYWO0GqBFpCFLKBjMbIiZzTOzQjO7Jc72JmY2Kto+xcxyYrbdGq2f\nZ2aDo3XZZjbezGab2Swz+0lM+TvNbIWZTY+WodV/m1UwfDjcfjv8/e/w0ENxi+Tmhp8KBhFpiPYZ\nDGaWDjwInAHkAheZWW65YpcDG9y9B/AAcG+0by4wAsgDhgAPRccrBn7m7rnAccA15Y75gLv3i5Zx\n1XqH++POO+Gss+C662DSpL02t2wJ2dkKBhFpmBI5Y+gPFLr7QnffAYwEhpUrMwx4Mnr8PHCqmVm0\nfqS7b3f3RUAh0N/di9z9YwB33wzMATpX/+3UkNLG6O7d4VvfgmXL9iqinkki0lAlEgydgdhvxuXs\n/SW+u4y7FwMbgXaJ7BtddjoKmBKz+lozm2FmT5hZm3iVMrMrzKzAzArWrFmTwNuoolatQmP01q1x\n74zu2xfmzoVdu2r+pUVEkimpjc9m1gL4N3Cdu2+KVj8MHAr0A4qA38fb190fcfd8d8/PzMysnQr2\n6bOnMfqqq8o0RuflwfbtsGBB7by0iEiyJBIMK4DsmOddonVxy5hZBtAKWFfZvmbWiBAKz7r7C6UF\n3H2Vu+9y9xLgUcKlrOQZNgzuuAP+8Q948MHdq9UzSUQaqkSCYRrQ08y6mVljQmPy2HJlxgKXRo/P\nB95xd4/Wj4h6LXUDegJTo/aHx4E57n5/7IHMLCvm6blA8q/k//KXcPbZcP31uxuj+/QJmxQMItLQ\n7DMYojaDa4HXCY3Eo919lpndbWbnRMUeB9qZWSHwU+CWaN9ZwGhgNvAacI277wJOBL4LDIzTLfU+\nM/vUzGYA3wSur6k3u9/S0sIlpUMPDXdGL1tGixaQk6MGaBFpeMwTGFG0vsvPz/eCgoLaf6G5c6F/\nf+jVC959l7O+1YwlS+DTT2v/pUVEapqZfeTu+eXX687nqjjssNCN9aOP4Mor+cZJzsyZofOSiEhD\noWCoqnPOCTfAPfUUP2v8Z/Lz4fvfhyVLkl0xEZGaoWDYH7ffDsOGkXHTTxlz3QRKSmDECNi5M9kV\nExGpPgXD/khLCzO/9exJ5xsu4okHt/LhhyEvREQOdAqG/dWyZZjxbeVK/ufLp/jhD+Hee+G115Jd\nMRGR6lGvpOpwh+OOg/Xr2frfuXz9hHSKiuCTT8L0nyIi9Zl6JdUGM7jpJigspNlrLzJ6dJjn5+KL\nNYaSiBy4FAzVNXw49OgB993HYb2dhx+GiRPhf/832RUTEdk/CobqSk+HG24IA+1NnMgll8Cll8Ld\nd8P48cmunIhI1SkYasIll0CHDnDffQD85S/Quzd8+9uwenWS6yYiUkUKhprQrBn8+Mfw6qswYwYt\nWsCoUbBhQ8iMkpJkV1BEJHEKhppy1VXQvDn87ncAHHEE/OEP8Prr8NvfJrluIiJVoGCoKW3bwg9+\nAM89B0uXAnDFFXDBBXDbbTB5cpLrJyKSIAVDTbr++nBvwx/+AITerI88AoccEobMWL8+yfUTEUmA\ngqEmde0KF10U0mDDBiBMHT1qFKxcCZddVmZ2UBGReknBUNNuvBG+/DIMlxHJzw/tDC+9BH/+cxLr\nJiKSAAVDTTviCBgyBP74R9i2bffqH/84jNh9ww2QjNE7REQSpWCoDTffHG5geOqp3avM4O9/h4MP\nhgsvhI0bk1g/EZFKKBhqwymnwLHHhq6rMYMmtW0bOi0tWRJ6LKm9QUTqIwVDbSgdXG/+/L3m/Tzx\nRPjVr2D0aHj00STVT0SkEhp2u7bs2hXGxWjbFqZMCWERKSmBM86ASZNg6lQ4/PAk1lNEUpaG3a5r\nsYPrTZpUZlNaGjz9NLRuDeefr/GURKR+UTDUpksvhczM3YPrxerQAf71L1i2DAYOhDVrklA/EZE4\nFAy1qXRwvXHj4NNP99p80knwyiuwYAGceiqsXZuEOoqIlJNQMJjZEDObZ2aFZnZLnO1NzGxUtH2K\nmeXEbLs1Wj/PzAZH67LNbLyZzTazWWb2k5jybc3sTTObH/1sU/23mURXXw1f+9ruwfXKGzgQXn45\ntFMPGgTr1tVx/UREytlnMJhZOvAgcAaQC1xkZrnlil0ObHD3HsADwL3RvrnACCAPGAI8FB2vGPiZ\nu+cCxwHXxBzzFuBtd+8JvB09P3CVDq73z3+G60ZxDBoU7oqeOxdOO01jKolIciVyxtAfKHT3he6+\nAxgJDCtXZhjwZPT4eeBUM7No/Uh33+7ui4BCoL+7F7n7xwDuvhmYA3SOc6wngeH799bqkXKD68Vz\n+umhZ+usWeFxNNSSiEidSyQYOgOxf+ouZ8+X+F5l3L0Y2Ai0S2Tf6LLTUcCUaFVHdy+KHq8EOiZQ\nx/qtdHjVmMH14hkyBF58MTRHDB4MX3xRh3UUEYkktfHZzFoA/wauc/dN5bd7uMki7o0WZnaFmRWY\nWcGaA6FLz003wZYt8Ne/Vlps6FD4979h+vQQDho6Q0TqWiLBsALIjnneJVoXt4yZZQCtgHWV7Wtm\njQih8Ky7vxBTZpWZZUVlsoC4vfzd/RF3z3f3/MzMzATeRpJVMLhePGedFbqyfvxx2GXTXpEpIlJ7\nEgmGaUBPM+tmZo0Jjcljy5UZC1waPT4feCf6a38sMCLqtdQN6AlMjdofHgfmuPv9lRzrUuClqr6p\neuumm2DVqnB32z4MGxaGzSgoCHdJb95cB/UTESGBYIjaDK4FXic0Eo9291lmdreZnRMVexxoZ2aF\nwE+JehK5+yxgNDAbeA24xt13AScC3wUGmtn0aBkaHese4DQzmw8Mip43DAMGhMkZyg2uV5Fzz4WR\nI8OIGkOHhitRIiK1TWMl1bV//StMBP3CC+GbPwGjR8PFF4cB+MaNg+bNa7mOIpISNFZSfXHeedC9\nO9x7b8Ljbl9wATzzDLz3Hpx9Nnz1VS3XUURSmoKhrpUOrjdlCrz7bsK7jRgRmiYmTlQ4iEjtUjAk\nw/e+V+HgepW5+GJ48kkYPz40Tm/dWjvVE5HUpmBIhmbN4Ec/gv/8B2bOrNKu3/lOmCL07bdh+PB9\n9nwVEakyBUOylA6ud++9Vd710kvhscfgjTfgnHM0ZLeI1CwFQ7K0awdXXRValb/znSoPjnTZZfDE\nE6HNoW/fMAifiEhNUDAk0//9H9x1V7hZ4fDDwylAFXz/++EGuE6dwmWlSy/V+EoiUn0KhmRq1Aju\nuAM+/BBatgyDI11zDXz5ZcKHOPzw0MHp9tvh2WfD87feqsU6i0iDp2CoD/Lz4aOPwvDcDz8M/frB\nBx8kvHvjxnD33TB5MrRoEeZ0uPbaKuWLiMhuCob6olkzuP9+eOcd2LkzzPt5222wY0fCh+jfPwy8\nd9118OCDIV8mT67FOotIg6RgqG8GDIAZM8K9Dr/5Tfi2jzNfdEWaNYMHHgj3OhQXwze+AbfcAtu3\n11qNRaSBUTDURy1bwuOPh65GRUXhUtN99yU08F6p0ny57LLQIzY/P8zxICKyLwqG+uycc8INcGed\nBTffDKecAgsWJLz7QQfBo4/CK6/A2rVw7LHwq1+FMwkRkYooGOq7zEx4/vkwUNLMmXDkkWGK0CqM\ninvmmTDrg03c/M2pFN7+D57Lvokt3zwbDj00TCBUWFiLb0BEDjQadvtAsmxZuDb01lth9p7HHgs3\nMcRatw5mz4Y5c8LP0sfLl+8usp3GzLdeND6yDz2Xj8caNw6NEr161fEbEpFkqmjYbQXDgaakJHRp\nvfFGaNo0dEFauXJPCMSOj9G8ORx2GOTmQp8+u38WNevOD67K4D//gUuOnsljiwbSqEl6CIfDDkve\nexOROqVgaGg++wwuuSTc3da6ddkv/9LH2dmQFv9qoXsYjO+WW6D9mtm832QgLVpAo0nvhP1FpMFT\nMDREJSVhjKW2bcFsvw6xZQv88Y8w5p65vLRlIM2bFLPh+XfIOatvDVdWROobzeDWEKWlhcH49jMU\nINwpfdtt8MbSw3juigl8uaMRzc/+Jr88dwZLltRcVUXkwKFgEADatIGf/a0XjSdPJKNFU3485pt8\nq8d/+dGPQhOGiKQOBYOU0f64HrSZPoFWnZozPv1Upjz0Ed27h7aI9euTXTsRqQsKBtnboYeS8d5E\nmh/ckg9aDOJnJ0/jvvugW7cwWN/mzcmuoIjUJgWDxNetG0ycSHq7NvzvB4OY/8wUBg6EX/4ybPr9\n7zXntEhDpWCQih1yCEyYAJmZHHrlabx442SmToVjjoEbboAePcItFVUYAFZEDgAKBqlc164hHA4+\nGAYP5tjt7/H662FK0e7dw9TVvXuHeyJSagymlSvhb3+DW28Nw6SLNCAJBYOZDTGzeWZWaGa3xNne\nxMxGRdunmFlOzLZbo/XzzGxwzPonzGy1mc0sd6w7zWyFmU2PlqH7//akRnTpEsKhUycYMgQmTeLk\nk2HSJHj11dBj9rLLIC8vzFJaUpLsCteSxYvDmObf+Eb4LK68Eu65J1xXE2lA9hkMZpYOPAicAeQC\nF5lZ+VtjLwc2uHsP4AHg3mjfXGAEkAcMAR6Kjgfwj2hdPA+4e79oGVe1tyS1olOnEA7Z2WGcpvHj\nMQs5MW0avPhimEnuoovCOH9jxlRpnL/6a84c+PWvw/Wzbt3gpz8Nre933hnmyTj33DBv98KFya6p\nSI1J5IyhP1Do7gvdfQcwEhhWrsww4Mno8fPAqWZm0fqR7r7d3RcBhdHxcPdJgDpAHkiyskI45OSE\nIVvffhsI99cNHw6ffALPPRfaHM49N8wx9NprB1hAuIdpVm+7bc8QI7/4BTRpAr/9bRiJdvr0MFd3\n377w5z+HubuvuuoAe6MiFUskGDoDy2KeL4/WxS3j7sXARqBdgvvGc62ZzYguN7WJV8DMrjCzAjMr\nWBM7cJzUro4dw2B7PXqEeSLGjdv9hZiWBiNGwKxZ8MQTYTy/M84IV14mTEhutSu1axe8+26Yczsn\nJ8xqdO+90LlzmCN1xYowR+oNN4ShymN17hzOKN54I6SiSANQHxufHwYOBfoBRUDcC7ju/oi757t7\nfmZmZl3WTzp0CHNT9+4dzhy6dQuNDM88AytWkJEB3/9+GOfvoYdg0SL45jfhtNPgww+TXfkYn30G\nP/xhuEx28smhi9WRR4aW9FWrwvDmV1+999Dm5V19dTg9uv563QUoDUIiwbACyI553iVaF7eMmWUA\nrYB1Ce5bhruvcvdd7l4CPEp06UnqmfbtQ9ekv/wl/IX90kvw3e+GhurDDoOrr6bx2Oe56ltrKSyE\n++8Pl5qOPx7OPhv++98k1r24OJwRHHEEPPtsSK1Ro8IpztixYb7tdu0SP156euihtG5dmGlP5EDn\n7pUuQAawEOgGNAY+AfLKlbkG+Gv0eAQwOnqcF5VvEu2/EEiP2S8HmFnuWFkxj68ntFFUWsdjjjnG\nJcl27XL/+GP33/3OfehQ9xYt3MNFJvcjj3S//nr/avTL/rs7Nnrr1mH1+ee7z5xZx/X873/djz46\nVOC889yLimru2DfcEI47aVLNHVOkFgEFHu97P97KvQrBUOAzYAFwW7TubuCc6HFT4F+ExuWpQPeY\nfW+L9psHnBGz/jnCpaKdhLaHy6P1TwOfAjOAsbFBUdGiYKiHduxwnzzZ/Ve/ch840L1Jk/Drlp7u\nO/O/7hNO/Lmf2fQtb8pXfswx7vfd5754cS3WZ+tW95//3D093b1jR/fnn6/519iyxf2QQ9z79HHf\ntq3mjy9SwyoKBs3HIHVj2zb44IPQNvHOOzB1KhQXs6Nxc8a0+h63r/kRn9Gb44+HCy+Eb31r35f2\nE/b++/D//h/MnRsuE/3+92EOi9owblxod7n7brj99tp5DZEaool6pH7ZvBneey9c24/6uC7odQa/\n2/lj/rbodLA0Tj45hMT558N+9S/YsgV+/vPQDtK1KzzyCJx+eo2/lb1ceGFoc5kxQ/NoS72miXqk\nfjnooNCX9R//gKVL4a67OHTTf3l40Rls7Z7Hy2c8xOaiLVx9dbh94vTTQxfYDRsSPP4bb4T7DP7y\nF7j2Wpg5s25CAeAPfwjzcV95pe5tkAOSgkGSr2PHcMPYkiXwzDM0aXcQZ467hoJVXVh9yQ3c88NF\nLFgAl18eip51VugZu2lTnGOtXx/6yg4eDM2ahfsT/vSnMFVdXcnKCkNljB8PTz9dd68rUkN0KUnq\nH/dww8Mf/wjPPw/u+Dnn8NmQn/DY/FMYNdpYtizcjDx0aLjL+qyzoM07/4ZrroG1a8PMQr/4RfjL\nPRlKSuCkk8K9EnPnhu69IvWM2hjkwLR8ebjxrPQ+gSOPpOTaHzPl0IsZOaYpzz8PJZ8X8aBdy3n+\nAmuyj8Ife4IOp/dLds3D5aujjoJvfztcMhOpZ9TGIAemLl3CkBPLlsFjj0FJCWk/uJzjL8jmjy1u\nY9ltf2XZQbmcnfYfftf+HrKWTaXj4H4cd1y4h+2zz5JY97594cYb4cknw2UlkQOEzhjkwOIeBl76\n059Czx/3MBjTY4/hPXsxZ04Y6fXFF8NYeBDGwTv33LAcfXQY9K/ObN0aAiI9PfRSStalLZE4dClJ\nGp5Fi2D+fBg0KIzgV87SpWH47xdfDHNHlJSEXqvDh4eQOOkkyMiog3q++WboEXXHHWGIbpF6QsEg\nKW3tWnj55RASb7wB27eH4abCCJEAAA7RSURBVJDOPDOMn3fCCWGIp1o7m/jOd2D06DBgVJ8+tfQi\nIlWjYBCJbNkCr78eQuK110KbNoSboU84ISwnngjHHht6vNaI1atD8vTtGy6FxTnDEalrCgaRONxD\nA/X774dl8uTQuxTCZaajjw4hceKJITCysqrxYo8/HobmeOyxcFOGSJIpGEQStHZtGNZp8uQQFtOm\nhaGeIEw9UXpGceKJYZ7r9PTKj7dbSQkMGBC6sc6dG+a1EEkiBYPIftqxI8wfUXpG8f77sHJl2Nay\nZegUNWBAWPr120eD9pw5YTKgCy4It2+LJJGCQaSGuMPixSEg3n03zFc0b17YllBQ/PKXYfTVN94I\n09qJJImCQaQWFRWFgJgwISzlg+KUU0JQHHUUZBRvC2cNxcXhslKNtXCLVI2CQaQOVRQUBx0UguK7\nXcYz4pGBlNx8K2n3/CaZVZUUpmAQSaJ4QfF3vsf3eJLPm3ZjZbcT4PjjOfi8E8g6/XCsUV3ceSep\nTsEgUo8UFcH7b3wJjz5Km9nv0WfDZDpRBMCXNKewbX825p1As4HHkzPiODIPa5fkGktDpGAQqce2\nb3PmvbmUVS9Oxj78gKxFk+m9bToZ7AJgQUZvlnQ5gR1HH0+bM0+gz3l9aNlaN8lJ9SgYRA4wW1Z9\nyYJRBWx6/QOaTZ9M95WTaVsSbtP+glZ82vw4Nhx6LK1yO5N9TAe6HtuRjE4dwv0RLVvW8WiBciBS\nMIgc6NxZP7WQ5aMns3PSB7SdN5lDNs8kjb3/D+9q1ATP7EB6VgesY8cQFh06hCnwYh937qxJhFJY\nRcGgFi6RA4UZbb/ek7Zf7wlcCoDv2Mmy6WuZPX4Vi6asZvWnq/hy0Wra7lxNx89Xkb1uNTkLVpLp\nM2jx1WrSdu7Y+7j5+WHI2eHDwxjldXWm4Q6bN4ezG6lXdMYg0sDs2BEGcf3wQ5gyJSyFhQBOG9vI\nSb1X842eqzi6y2ryMuaR+eFY0qdNCTv36BECYtgwOP74Koz3kQD3UJHSrlkTJsDnn0P37uFGj1NO\nCUPd5uToMlgd0aUkkRS2di1MnVo2LDZu3LP9iPafc/FBLzN42xj6rnqbjJKd7GidybbTz+FrFw0n\nY/CpVb8Rr6IgADj44HDHX15emFFp0iRYvz5sy87eExSnnBLCSkFRK6oVDGY2BPgjkA485u73lNve\nBHgKOAZYB1zo7oujbbcClwO7gB+7++vR+ieAs4DV7t435lhtgVFADrAYuMDdN1RWPwWDSNWUlIRR\nZT/+GBYuDHMelS5fLN3E6SWvMpwxnMl/aMlmvrTmFLQbwrzc4Ww88UyyctvQrVv4475jx2jYj0SC\noHTp1avsl31JCcyaFW72mDQp/Fy9OmzLygpnEqVB0aePgqKG7HcwmFk68BlwGrAcmAZc5O6zY8pc\nDRzh7lea2QjgXHe/0MxygeeA/kAn4C2gl7vvMrOTgS3AU+WC4T5gvbvfY2a3AG3c/ebK6qhgEKk5\nxcVhiu1Fi2DJZ9uxiRPoUjCGI5e8RObOIopJZyKnMIbhTOYEjuFjBjeZwDd2TaBDcQiCTc0Ppqj3\nADYfPQAGDKB1/14cnGW0aJFgJdzDXYATJ+5ZSkMmMzMExcknh2n4unQJsy7V5GWvFFGdYDgeuNPd\nB0fPbwVw9/+LKfN6VOYDM8sAVgKZwC2xZWPLRc9zgFfKBcM8YIC7F5lZFjDB3XtXVkcFg0gdKCmB\nggJ2/msMJS+MocnCObs3bWx2MJ+0GcB7jQbw+rYBTF7bi+Jde/9V36JFOHnIygo/O3WCQw8NJxA9\ne8Ihh1Tw/e4OCxbsOZuYOBGWLNmz3SzMtNShQwiOzMyyj8s/b9eujuZ1rSVLlsBbb4XlV78KH+J+\nqE6vpM7Aspjny4GvV1TG3YvNbCPQLlr/Ybl9O+/j9Tq6e1H0eCXQMV4hM7sCuAKga9eu+34XIlI9\naWnQvz+N+veH3/4m/EX/0UdwzDG06tWLk804Gfg5IUPWrw93eK9cGf/njBkwbhx8+eWel2jUKHzH\n9ewZltLA6NnT6Ny9B2k9esBll4XCS5aEhpNVq8JlpzVrwrJ6dbgsNWHCnun5yosNkqyssHTqtOdn\n6eOsLGjevJY/2ARs2ADvvLMnDEJvglC/xYv3OxgqUq8j093dzOKe0rj7I8AjEM4Y6rRiIgK9e4cl\njrS0cHtE+/Zw+OEVH8I9fK/Pnx/aPObP3/P4zTf3TJAEoe27R4/YwDiEnj0P4ZCvh+/xuCcAxcUh\nHGJDI/bx6tXR+CTvh0tVO+J0523ZsmxYlA+Q7OxwP0ijRlX7/CqzbVuY/KM0CAoKwofVokVoo7n2\n2jBkey21tyQSDCuA7JjnXaJ18cosjy4ltSI0Qieyb3mrzCwr5lLS6gTqKCIHILNwSengg8Oos7FK\nSmDFir0DY9YsePll2LlzT9m0tPAd3bXrniU7G7p2zaBr14507dqRNnn7+A51D3+Zf/55CIvPPy/7\nuDRAiopg+/a930hpBcIL7720bVtxBUpKQh/j0iB4913YujVcVzvuuDCHx6BB0L9/zQZQBRJpY8gg\nND6fSvhSnwZc7O6zYspcAxwe0/h8nrtfYGZ5wD/Z0/j8NtDT3XdF++WwdxvDb4F1MY3Pbd39psrq\nqDYGkdRSXByuJBUWwtKlobF86dI9y7Jle//x37z53t/b2dmh7bp0SahxvDRAiopCcsV78aVL9w6P\nZs32DotWrcKZwdtv77nslZcXQmDQoNDAXos3AFa3u+pQ4A+E7qpPuPuvzexuoMDdx5pZU+Bp4Chg\nPTDC3RdG+94GXAYUA9e5+6vR+ueAAUB7YBXwS3d/3MzaAaOBrsASQnfV9ZXVT8EgIrFKSsJVovLf\n2bHf26tW7b1fq1bhqlBpUMQ+Ln1e2R/+u7mHy1UVvfjSpXvmh83KCpeFBg2CU08NZx51RDe4iYjE\n2LYNli8Pf/QvXx7/cVFR+I6P1bRp2dDIySm7ZGdDkyYJVGD79nCWkJWVtPsyNFaSiEiMpk1DY3aP\nHhWX2bkz/GFfUXi89x6MHAm7du3Zp7S5IScndL8tHxxdu0bB0aRJnZ4dVIWCQUSkAo0ahTOA7OyK\nyxQXh7bpxYv3Xj74AEaN2js4srL2hETr1mHK1xYtws/YJd66Zs1q/wRDwSAiUg0ZGXvakk8+ee/t\nlQXHtGmwaVMYZDa2a25l0tLKBsYjj+zdo6u6FAwiIrVoX8FRaudO2LIlhETpz9ilonWtWtVCnWv+\nkCIiUlWNGkGbNmFJNk0aKyIiZSgYRESkDAWDiIiUoWAQEZEyFAwiIlKGgkFERMpQMIiISBkKBhER\nKaNBjK5qZmsIQ3Tvj/bA2hqsTk1T/apH9ase1a/66nMdD3H3zPIrG0QwVIeZFcQbdra+UP2qR/Wr\nHtWv+g6EOpanS0kiIlKGgkFERMpQMMAjya7APqh+1aP6VY/qV30HQh3LSPk2BhERKUtnDCIiUoaC\nQUREykiZYDCzIWY2z8wKzeyWONubmNmoaPsUM8upw7plm9l4M5ttZrPM7Cdxygwws41mNj1a7qir\n+kWvv9jMPo1euyDOdjOzP0Wf3wwzO7oO69Y75nOZbmabzOy6cmXq9PMzsyfMbLWZzYxZ19bM3jSz\n+dHPuFOymNmlUZn5ZnZpHdbvt2Y2N/r3e9HMWlewb6W/C7VYvzvNbEXMv+HQCvat9P96LdZvVEzd\nFpvZ9Ar2rfXPr9rcvcEvQDqwAOgONAY+AXLLlbka+Gv0eAQwqg7rlwUcHT0+CPgsTv0GAK8k8TNc\nDLSvZPtQ4FXAgOOAKUn8t15JuHEnaZ8fcDJwNDAzZt19wC3R41uAe+Ps1xZYGP1sEz1uU0f1Ox3I\niB7fG69+ifwu1GL97gRuSODfv9L/67VVv3Lbfw/ckazPr7pLqpwx9AcK3X2hu+8ARgLDypUZBjwZ\nPX4eONXMrC4q5+5F7v5x9HgzMAfoXBevXYOGAU958CHQ2syyklCPU4EF7r6/d8LXCHefBKwvtzr2\nd+xJYHicXQcDb7r7enffALwJDKmL+rn7G+5eHD39EOhS06+bqAo+v0Qk8n+92iqrX/S9cQHwXE2/\nbl1JlWDoDCyLeb6cvb94d5eJ/nNsBNrVSe1iRJewjgKmxNl8vJl9YmavmllenVYMHHjDzD4ysyvi\nbE/kM64LI6j4P2QyPz+Aju5eFD1eCXSMU6a+fI6XEc4A49nX70Jtuja61PVEBZfi6sPn9w1glbvP\nr2B7Mj+/hKRKMBwQzKwF8G/gOnffVG7zx4TLI0cCfwbG1HH1TnL3o4EzgGvM7OQ6fv19MrPGwDnA\nv+JsTvbnV4aHawr1sq+4md0GFAPPVlAkWb8LDwOHAv2AIsLlmvroIio/W6j3/5dSJRhWANkxz7tE\n6+KWMbMMoBWwrk5qF16zESEUnnX3F8pvd/dN7r4lejwOaGRm7euqfu6+Ivq5GniRcMoeK5HPuLad\nAXzs7qvKb0j25xdZVXp5Lfq5Ok6ZpH6OZvY94Czg21F47SWB34Va4e6r3H2Xu5cAj1bwusn+/DKA\n84BRFZVJ1udXFakSDNOAnmbWLfqrcgQwtlyZsUBpD5DzgXcq+o9R06Jrko8Dc9z9/grKHFza5mFm\n/Qn/dnUSXGbW3MwOKn1MaKScWa7YWOCSqHfSccDGmMsmdaXCv9SS+fnFiP0duxR4KU6Z14HTzaxN\ndKnk9GhdrTOzIcBNwDnu/lUFZRL5Xait+sW2WZ1bwesm8n+9Ng0C5rr78ngbk/n5VUmyW7/raiH0\nmvmM0GPhtmjd3YT/BABNCZcgCoGpQPc6rNtJhMsKM4Dp0TIUuBK4MipzLTCL0MviQ+CEOqxf9+h1\nP4nqUPr5xdbPgAejz/dTIL+O/32bE77oW8WsS9rnRwioImAn4Tr35YQ2q7eB+cBbQNuobD7wWMy+\nl0W/h4XA9+uwfoWE6/Olv4OlvfQ6AeMq+12oo/o9Hf1uzSB82WeVr1/0fK//63VRv2j9P0p/52LK\n1vnnV91FQ2KIiEgZqXIpSUREEqRgEBGRMhQMIiJShoJBRETKUDCIiEgZCgYRESlDwSAiImX8fzqJ\nY+PC7JucAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0RtAaVQ9_S3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f45108fb-f82c-4d55-b906-1d4483c055a9"
      },
      "source": [
        "plt.plot(train_acc_array,'b')\n",
        "plt.plot(test_acc_array,'r')\n",
        "plt.title(\"Accuracy Curves\");"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6EVE0pyCXkQkzSnoRUTS3P8HNgmaWGMngCUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQbDishc_fLs",
        "colab_type": "text"
      },
      "source": [
        "**Try running for more number of epochs and see if the accuracy increases? What about Validation Accuracy?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX9L-n6Q9_S5",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "- https://pytorch.org/tutorials/advanced/cpp_frontend.html\n",
        "- https://github.com/pytorch/examples/blob/master/cpp/custom-dataset/custom-dataset.cpp"
      ]
    }
  ]
}